{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing Examples V1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler, DiffusionPipeline\n",
    "from ptp import invutils, frq_ptputils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Version\n",
    "We recommend using the stable diffusion version of :\n",
    "\n",
    "- \"CompVis/stable-diffusion-v1-4\"\n",
    "- \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "\n",
    "### Hyperparameter Sets\n",
    "- We mainly modify two sets of hyperparameters TS=[t_M, t_{M-1}, ..., t_0], FS={s_N, s_{N-1}, ..., s_0}. TS are the timesteps at which we change the filter size. FS are the filter sizes. The combination of them results in a filter sequence: [t:981, s_N, t_M, s_{N-1}, t_{M-1}, ..., t_0, s_0]\n",
    "- Of course, you are free to tune the hyperparamter that controls the \"Clearing low\" procedure, which aiming at further eliminating some small values left afther frequency truncation.\n",
    "\n",
    "\n",
    "### Principle for Hyperparameter Selection\n",
    "- Generally, with considering the editying type, we recommand trying a earlier response period and smaller filter size(allowing more LFC of the guidance) for larger shape changes.\n",
    "- For larger change of color, we recommand adopting the two-stage method, and with considering the edit-friendly inversion technique, which blends extra noise into the latents. Codes of this part will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the device and backbone model\n",
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "NUM_INFER_STEPS = 50\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012,\n",
    "                           beta_schedule=\"scaled_linear\", clip_sample=False, \n",
    "                           set_alpha_to_one=False, steps_offset=1)\n",
    "model = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", scheduler=scheduler).to(DEVICE)\n",
    "model.scheduler.set_timesteps(NUM_INFER_STEPS)\n",
    "\n",
    "g_seed = 8888\n",
    "g_cpu = torch.Generator().manual_seed(8888)\n",
    "\n",
    "\n",
    "# specify the image path and save path\n",
    "def set_img(iname=\"11102.jpg\", idir='./DATASET', sdir='./outputs/test'):\n",
    "    img_dir = idir\n",
    "    img_path = os.path.join(img_dir, iname)\n",
    "    save_dir = sdir\n",
    "    # the vae-reconstruct image is saved to show the possible difference caused by vae encoder\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    return save_dir, img_path\n",
    "\n",
    "# compute the inverted latent for editing. Fix-point iteration is used.\n",
    "def get_latents(iname, ipath, sdir):\n",
    "    img_np = invutils.load_512(ipath)\n",
    "    img_latn = invutils.img2latn(img_np, model, DEVICE)\n",
    "    img_latn_rec = invutils.latn2img(img_latn, model)[0]\n",
    "    Image.fromarray(img_latn_rec).save(os.path.join(sdir, iname[:-4]+\"vae-rec.png\"))\n",
    "    uncond_emb = invutils.encode_text(\"\", model)\n",
    "    xT, xts = invutils.ddim_inversion_null_fixpt(img_latn, model, uncond_emb, save_all=True, FP_STEPS=5, \n",
    "                                                    INV_STEPS=NUM_INFER_STEPS,)\n",
    "\n",
    "    return xT, xts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing of Objects\n",
    "\n",
    "The target prompt should follow the principle mentioned in the paper.\n",
    "\n",
    "- For cases of changing a single object, use a simple one that only describes the target(effect).\n",
    "- For cases of changing a object while the editing effect affects backgrounds, use a target prompt that contains the description of surrounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"11102.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a marmot\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(801, 781, 581), FS=(32, 32, 10, 10), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"11207.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a crown on the hair\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(801, 681, 581), FS=(32, 32, 2, 10), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"11201.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"hat\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(801, 781, 581), FS=(32, 32, 32, 20), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding of Objects\n",
    "\n",
    "The task of adding object is difficult for the current version of our method, even for the P2P with adopting blending. In most cases the methods are changing part of the images to the target object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"21207.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a woman surrounded by snakes and roses\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(801, 781, 581), FS=(32, 32, 10, 10), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing of Shape and Poses\n",
    "\n",
    "- For the changing of poses, drastically changes often happen in earlier generation process with some steps being crucial during the response period.\n",
    "- For the changing of shapes, though large alteration happens the response period seems to be later and lasting longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"21207.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a greyhound jumping\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(961, 881, 781), FS=(32, 4, 8, 16), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"12408.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a red heart in the snow\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(901, 801, 601, 501), FS=(32, 2, 2, 32, 32), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing of Materials\n",
    "\n",
    "- The response period usually lies in later process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"72100.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a bronze horse\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(681, 581, 481), FS=(32, 20, 8, 1), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"71102.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a plastic butterfly\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(781, 681, 581), FS=(32, 2, 4, 4), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing of Styles\n",
    "\n",
    "- For different styles, the hyperparameter sets differ greatly\n",
    "- In most cases, a full description of the original image is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"91102.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"kids crayon drawing of a colorful cat with bubbles and stars on it\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(801, 781, 581), FS=(4, 4, 2, 2), HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iname = \"92206.jpg\"\n",
    "save_dir, img_path = set_img(iname)\n",
    "xT, xts = get_latents(iname, img_path, save_dir)\n",
    "prompt = [\"a cartoon painting of a woman in white sitting on a bench\"]\n",
    "res_latents = frq_ptputils.frq_img_gen(model, prompt, g_seed=g_seed,\n",
    "                     latent=xT, mod_guidance_frq =True,\n",
    "                    save_dir=save_dir, guidance_scale=7.5, \n",
    "                    TS=(881, 781, 581), FS=(6, 4, 4, 4),  HS=(32, 32, 32, 32, 32, 32),\n",
    "                    filter_shape = 'sq', \n",
    "                    # remove = True,\n",
    "                    # generate_mask=True, gen_MSK_THRS=0.025,\n",
    "                    # guide_mask=True, \n",
    "                    # reverse_mask=True,\n",
    "                    num_infer_steps = NUM_INFER_STEPS,\n",
    "                    clear_low = True,\n",
    "                    record_time = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More examples will be added later"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
